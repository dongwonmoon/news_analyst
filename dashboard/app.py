import os
from dotenv import load_dotenv

import streamlit as st
import psycopg2
import pandas as pd
from collections import Counter

from wordcloud import WordCloud
import matplotlib.pyplot as plt

load_dotenv()

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="ì‹¤ì‹œê°„ ë‰´ìŠ¤ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)


# --- DB ì—°ê²° ë° ë°ì´í„° ë¡œë”© (ìºì‹±ì„ í†µí•œ ë°±ì—”ë“œ ìµœì í™”) ---
@st.cache_resource
def get_db_connection():
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ DB ì ‘ì† ì •ë³´ë¥¼ ê°€ì ¸ì™€ ì—°ê²°í•©ë‹ˆë‹¤."""
    conn = psycopg2.connect(
        host=os.getenv("POSTGRES_HOST"),
        port=os.getenv("POSTGRES_PORT"),
        dbname=os.getenv("POSTGRES_DB"),
        user=os.getenv("POSTGRES_USER"),
        password=os.getenv("POSTGRES_PASSWORD"),
    )
    return conn


@st.cache_data(ttl=300)
def load_data():
    """ìµœê·¼ 24ì‹œê°„ì˜ ë¶„ì„ëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    conn = get_db_connection()
    query = """
        SELECT url, title, news_time, sentiment, sentiment_score, keywords, cluster_id
        FROM analyzed_news
        WHERE news_time >= NOW() - INTERVAL '1 day';
    """
    df = pd.read_sql_query(query, conn)
    df["news_time"] = pd.to_datetime(df["news_time"])
    return df


# --- ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (ë°±ì—”ë“œ ë¡œì§) ---
def get_wordcloud_data(df: pd.DataFrame) -> Counter:
    """ë°ì´í„°í”„ë ˆì„ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ë¹ˆë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    keywords = df["keywords"].dropna().sum()
    return Counter(keywords)


# --- ëŒ€ì‹œë³´ë“œ UI ë Œë”ë§ ---
st.title("ğŸ“Š ì‹¤ì‹œê°„ ë‰´ìŠ¤ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ")
st.markdown("ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆì˜ ë‰´ìŠ¤ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

# ë°ì´í„° ë¡œë“œ
try:
    df = load_data()
    if df.empty:
        st.warning("ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆ ë¶„ì„ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
except Exception as e:
    st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë˜ëŠ” ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()

# --- 1. ë©”ì¸ ë¸Œë¦¬í•‘ ---
st.header("ğŸ“Œ ë©”ì¸ ë¸Œë¦¬í•‘")
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ’¬ ì‹¤ì‹œê°„ ì´ìŠˆ ë§µ")
    word_counts = get_wordcloud_data(df)
    if word_counts:
        wc = WordCloud(
            font_path="font/NanumGothic.ttf",
            background_color="white",
            width=800,
            height=400,
        ).generate_from_frequencies(word_counts)
        fig, ax = plt.subplots()
        ax.imshow(wc, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)
    else:
        st.text("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

with col2:
    st.subheader("ğŸ˜Š ì „ì²´ ë‰´ìŠ¤ ê°ì„± ì§€ìˆ˜")
    sentiment_counts = df["sentiment"].value_counts()
    st.bar_chart(sentiment_counts)

st.subheader("ğŸ“ˆ ì£¼ìš” í† í”½ íƒ€ì„ë¼ì¸")
timeline_df = (
    df.set_index("news_time")
    .groupby([pd.Grouper(freq="H"), "cluster_id"])
    .size()
    .unstack(fill_value=0)
)
st.line_chart(timeline_df)

# --- 2. ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„ ---
st.header("ğŸ” ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„")
all_clusters = df["cluster_id"].dropna().unique().astype(int)
selected_cluster = st.selectbox(
    "ë¶„ì„í•  í† í”½(êµ°ì§‘ ID)ì„ ì„ íƒí•˜ì„¸ìš”:", sorted(all_clusters)
)

if selected_cluster:
    cluster_df = df[df["cluster_id"] == selected_cluster]
    st.markdown(f"### í† í”½ #{selected_cluster} ìƒì„¸ ì •ë³´")
    st.dataframe(
        cluster_df[["title", "news_time", "sentiment"]].sort_values(
            "news_time", ascending=False
        )
    )
