# dashboard/app.py

import streamlit as st
import psycopg2
import pandas as pd
from collections import Counter

# ì›Œë“œí´ë¼ìš°ë“œ, ì°¨íŠ¸ ë“± ì‹œê°í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” requirements.txtì— ì¶”ê°€ í•„ìš”
# ì˜ˆ: from wordcloud import WordCloud
import matplotlib.pyplot as plt

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(
    page_title="ì‹¤ì‹œê°„ ë‰´ìŠ¤ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- DB ì—°ê²° ë° ë°ì´í„° ë¡œë”© (ìºì‹±ì„ í†µí•œ ë°±ì—”ë“œ ìµœì í™”) ---


# DB ì»¤ë„¥ì…˜ì€ ë¦¬ì†ŒìŠ¤ë¡œ ì·¨ê¸‰, í•œë²ˆë§Œ ìƒì„± í›„ ì¬ì‚¬ìš©
@st.cache_resource
def get_db_connection():
    """Streamlit secretsë¥¼ ì‚¬ìš©í•˜ì—¬ DBì— ì—°ê²°í•©ë‹ˆë‹¤."""
    creds = st.secrets["postgres"]
    conn = psycopg2.connect(
        host=creds["host"],
        port=creds["port"],
        dbname=creds["dbname"],
        user=creds["user"],
        password=creds["password"],
    )
    return conn


# ë°ì´í„°ëŠ” 5ë¶„(300ì´ˆ)ë§ˆë‹¤ ìƒˆë¡œê³ ì¹¨. ê·¸ ì‚¬ì´ì—ëŠ” ìºì‹œëœ ë°ì´í„°ë¥¼ ì‚¬ìš©.
@st.cache_data(ttl=300)
def load_data():
    """ìµœê·¼ 24ì‹œê°„ì˜ ë¶„ì„ëœ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    conn = get_db_connection()
    query = """
        SELECT url, title, news_time, sentiment, sentiment_score, keywords, cluster_id
        FROM analyzed_news
        WHERE news_time >= NOW() - INTERVAL '1 day';
    """
    df = pd.read_sql_query(query, conn)
    df["news_time"] = pd.to_datetime(df["news_time"])
    return df


# --- ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (ë°±ì—”ë“œ ë¡œì§) ---


def get_wordcloud_data(df: pd.DataFrame) -> Counter:
    """ë°ì´í„°í”„ë ˆì„ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ë¹ˆë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤."""
    keywords = df["keywords"].dropna().sum()  # ëª¨ë“  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨
    return Counter(keywords)


# --- ëŒ€ì‹œë³´ë“œ UI ë Œë”ë§ ---

st.title("ğŸ“Š ì‹¤ì‹œê°„ ë‰´ìŠ¤ íŠ¸ë Œë“œ ëŒ€ì‹œë³´ë“œ")
st.markdown("ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆì˜ ë‰´ìŠ¤ íŠ¸ë Œë“œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

# ë°ì´í„° ë¡œë“œ
try:
    df = load_data()
    if df.empty:
        st.warning("ì§€ë‚œ 24ì‹œê°„ ë™ì•ˆ ë¶„ì„ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.stop()
except Exception as e:
    st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ë˜ëŠ” ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.stop()


# --- 1. ë©”ì¸ ë¸Œë¦¬í•‘ ---
st.header("ğŸ“Œ ë©”ì¸ ë¸Œë¦¬í•‘")
col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ğŸ’¬ ì‹¤ì‹œê°„ ì´ìŠˆ ë§µ")
    word_counts = get_wordcloud_data(df)
    if word_counts:
        # ì›Œë“œí´ë¼ìš°ë“œ ìƒì„± ë° í‘œì‹œ
        wc = WordCloud(
            font_path="font/NanumGothic.ttf",
            background_color="white",
            width=800,
            height=400,
        ).generate_from_frequencies(word_counts)
        fig, ax = plt.subplots()
        ax.imshow(wc, interpolation="bilinear")
        ax.axis("off")
        st.pyplot(fig)
    else:
        st.text("í‚¤ì›Œë“œ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

with col2:
    st.subheader("ğŸ˜Š ì „ì²´ ë‰´ìŠ¤ ê°ì„± ì§€ìˆ˜")
    sentiment_counts = df["sentiment"].value_counts()
    st.bar_chart(sentiment_counts)

st.subheader("ğŸ“ˆ ì£¼ìš” í† í”½ íƒ€ì„ë¼ì¸")
# cluster_id ë³„ ì‹œê°„ëŒ€ë³„ ê¸°ì‚¬ ìˆ˜ ê³„ì‚°
timeline_df = (
    df.set_index("news_time")
    .groupby([pd.Grouper(freq="H"), "cluster_id"])
    .size()
    .unstack(fill_value=0)
)
st.line_chart(timeline_df)


# --- 2. ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„ ---
st.header("ğŸ” ì´ìŠˆ ì‹¬ì¸µ ë¶„ì„")
# êµ°ì§‘(í´ëŸ¬ìŠ¤í„°) IDë¥¼ ê¸°ì¤€ìœ¼ë¡œ í•„í„°ë§
all_clusters = df["cluster_id"].dropna().unique().astype(int)
selected_cluster = st.selectbox(
    "ë¶„ì„í•  í† í”½(êµ°ì§‘ ID)ì„ ì„ íƒí•˜ì„¸ìš”:", sorted(all_clusters)
)

if selected_cluster:
    cluster_df = df[df["cluster_id"] == selected_cluster]
    st.markdown(f"### í† í”½ #{selected_cluster} ìƒì„¸ ì •ë³´")

    # ê´€ë ¨ ê¸°ì‚¬ ëª©ë¡ í‘œì‹œ
    st.dataframe(
        cluster_df[["title", "news_time", "sentiment"]].sort_values(
            "news_time", ascending=False
        )
    )
